---
title: "提示工程的最佳实践"
url: "https://claude.com/blog/best-practices-for-prompt-engineering"
---

# 提示工程的最佳实践

[上下文工程 (Context engineering)](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents) 已成为与 LLM 合作中日益重要的一部分，而提示工程 (Prompt engineering) 是其重要的基石。

[提示工程](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices) 是一门构建指令以从 AI 模型获得更好输出的手艺。它是关于你如何措辞查询、指定风格、提供上下文以及引导模型行为以实现你的目标。

模糊的指令和精心制作的提示之间的区别，可能意味着通用输出与完全符合你需求的输出之间的差距。结构糟糕的提示可能需要多次来回交流才能澄清意图，而精心设计的提示则可以一次性达成目标。

为了帮助你开始，我们汇集了我们团队的一些最佳实践，包括旨在立即改善结果的实用方法。我们将从你今天就可以使用的简单习惯开始，然后扩展到用于复杂项目的高级方法。

## 如何使用提示工程

在最基本的层面上，提示工程只是修改你传递给 LLM 的查询。通常，它只是在你提出实际请求之前向查询添加信息——但知道 *哪些* 信息是 *正确* 的共享信息，是设计出色且有效提示的秘诀。

### 核心技巧

这些提示工程技巧构成了有效 AI 交互的基础。坚持使用它们，可以看到响应质量的立即改善。

#### 明确且清晰

现代 AI 模型对清晰、明确的指令反应非常好。不要假设模型会推断出你想要什么——直接说出来。使用简单的语言，毫无歧义地陈述你究竟想要什么。

**关键原则**：准确告诉模型你想看到什么。如果你想要全面的输出，就要求它。如果你想要特定的功能，列出它们。像 Claude 这样的现代模型尤其受益于明确的指导。

**示例：创建分析仪表板**

**模糊**："创建一个分析仪表板"

**明确**："创建一个分析仪表板。包含尽可能多的相关功能和交互。超越基础，创建一个全功能的实现。"

第二个版本明确要求全面的功能，并发出信号表明你希望模型超越最低限度。

**最佳实践**：

*   以直接的动作动词开头："编写"、"分析"、"生成"、"创建"
*   跳过开场白，直奔主题
*   说明你希望输出包含什么，而不仅仅是做什么
*   对质量和深度的期望要具体

#### 提供背景和动机

解释 *为什么* 某事很重要，有助于 AI 模型更好地理解你的目标并提供更有针对性的响应。这对能够推理你潜在目标的较新模型特别有效。

**示例：格式偏好**

**效果较差**："永远不要使用要点"

**更有效**："我更喜欢自然段落形式的回复，而不是要点，因为我发现流畅的散文更容易阅读，也更具对话性。要点对于我随意的学习风格来说显得太正式和像清单了。"

第二个版本帮助模型理解规则背后的推理，这使其能够就相关的格式选择做出更好的决定。

**何时提供背景**：

*   解释输出的目的或受众
*   澄清为什么存在某些限制
*   描述将如何使用输出
*   指出你试图解决什么问题

#### 具体化

提示工程中的具体性意味着用明确的指导方针和要求来构建你的指令。你对自己想要的东西越具体，结果就越好。

**示例：膳食计划**

**模糊**："制定地中海饮食膳食计划"

**具体**："为糖尿病前期管理设计一份地中海饮食膳食计划。每日 1,800 卡路里，强调低血糖生成指数食物。列出早餐、午餐、晚餐和一种零食，并附带完整的营养细分。"

**什么让提示足够具体？**

包括：

*   清晰的限制（字数、格式、时间表）
*   相关背景（受众是谁，目标是什么）
*   期望的输出结构（表格、列表、段落）
*   任何要求或限制（饮食需求、预算限制、技术限制）

#### 使用示例

示例并不总是必要的，但在解释概念或演示特定格式时，它们会大放异彩。也被称为单样本 (one-shot) 或少样本 (few-shot) 提示，示例通过展示而不是讲述，澄清了仅通过描述难以表达的微妙要求。

**现代模型的重要说明**：Claude 4.x 和类似的高级模型非常关注示例中的细节。确保你的示例与你想要鼓励的行为一致，并尽量减少你想要避免的模式。

**示例：文章摘要**

**没有示例**："总结这篇文章"

```plaintext
这是一个我想要的摘要风格的示例：

文章：[关于 AI 监管的文章链接]
摘要：欧盟通过了针对高风险系统的全面《人工智能法案》。关键条款包括透明度要求和人工监督授权。2026 年生效。

现在用同样的风格总结这篇文章：[你的新文章链接]
```

**何时使用示例**：

*   期望的格式比描述更容易展示
*   你需要特定的语气或风格
*   任务涉及微妙的模式或惯例
*   简单的指令未能产生一致的结果

**专业提示**：从一个示例（单样本）开始。只有在输出仍然不符合你的需求时才添加更多示例（少样本）。

#### 允许 Claude 表达不确定性

给予 AI 明确的许可来表达不确定性而不是猜测。这减少了幻觉并提高了可靠性。

**示例**："分析这些财务数据并确定趋势。如果数据不足以得出结论，请说明，而不是进行推测。"

这个简单的添加通过允许模型承认局限性，使响应更值得信赖。

[**在 Claude 中尝试**](https://claude.ai/) **这些技巧。**

## 高级提示工程技巧

这些核心习惯会让你走得很远，但你可能仍会遇到需要更复杂方法的情况。当你构建代理式解决方案、处理复杂的数据结构或需要分解多阶段问题时，高级提示工程技巧就会大放异彩。

### 预填 AI 的响应

预填允许你为 AI 开始响应，引导格式、语气或结构。这种技术对于强制输出格式或跳过开场白特别强大。

**何时使用预填**：

*   你需要 AI 输出 JSON、XML 或其他结构化格式
*   你想跳过对话式的开场白，直接进入内容
*   你需要保持特定的声音或角色
*   你想控制 AI 如何开始其响应

**示例：强制 JSON 输出**

没有预填，Claude 可能会说："这是你请求的 JSON：{...}"

使用预填（API 用法）：

```python
messages=[
    {"role": "user", "content": "Extract the name and price from this product description into JSON."},
    {"role": "assistant", "content": "{"}
]
```

AI 将从左大括号继续，仅输出有效的 JSON。

**注意**：在聊天界面中，你可以通过非常明确的方式来近似这一点："仅输出有效的 JSON，不要有开场白。以左大括号开始你的响应。"

### 思维链 (Chain of Thought) 提示

思维链 (CoT) 提示涉及在回答之前请求逐步推理。这种技术有助于受益于结构化思维的复杂分析任务。

**现代方法**：Claude 提供了一个 [扩展思维 (extended thinking)](https://www.anthropic.com/news/visible-extended-thinking) 功能，可以自动化结构化推理。如果可用，扩展思维通常优于手动思维链提示。然而，理解手动 CoT 对于扩展思维不可用的情况（例如免费的 [Claude.ai](http://claude.ai) 计划）或当你需要可以审查的透明推理时仍然很有价值。

**何时使用思维链**：

*   扩展思维不可用
*   你需要可以审查的透明推理
*   任务需要多个分析步骤
*   你想确保 AI 考虑特定因素

思维链有三种常见的实现方式：

**基本思维链**

只需在你的指令中添加"一步步思考"。

```plaintext
起草给捐赠者的个性化电子邮件，请求为今年的"关爱儿童"项目捐款。

项目信息：
<program>
{{PROGRAM_DETAILS}}
</program>

捐赠者信息：
<donor>
{{DONOR_DETAILS}}
</donor>

在写邮件之前一步步思考。
```

**引导式思维链**

构建你的提示以提供具体的推理阶段。

```javascript
在写邮件之前先思考。首先，考虑到这位捐赠者的捐赠历史，思考什么信息可能会吸引他们。然后，考虑"关爱儿童"项目的哪些方面会引起他们的共鸣。最后，利用你的分析编写个性化的捐赠者邮件。
```

**结构化思维链**

使用标签将推理与最终答案分开。

```javascript
在写邮件之前，先在 <thinking> 标签中思考。首先，分析什么信息会吸引这位捐赠者。然后，确定相关的项目方面。最后，利用你的分析，在 <email> 标签中编写个性化的捐赠者邮件。
```

**注意**：即使在扩展思维可用时，显式的 CoT 提示对于复杂任务仍然有益。这两种方法是互补的，而不是互斥的。

### 控制输出格式

对于现代 AI 模型，有几种控制响应格式的有效方法：

**1\. 告诉 AI 做什么，而不是不做什么**

与其说："不要在你的回复中使用 markdown"，不如试着说："你的回复应该由流畅的散文段落组成"。

**2\. 使你的提示风格与期望的输出相匹配**

你在提示中使用的格式风格可能会影响 AI 的响应风格。如果你想要最少的 markdown，请在你的提示中减少 markdown。

**3\. 对格式偏好要明确**

为了对格式进行详细控制：

```plaintext
在撰写报告或分析时，使用完整的段落以清晰、流畅的散文形式书写。使用标准的段落分隔进行组织。主要保留 markdown 用于行内代码、代码块和简单的标题。

除非你在展示真正的离散项目，列表格式是最佳选择，或者用户明确要求列表，否则不要使用有序列表或无序列表。

不要用要点列出项目，而是将它们自然地融入句子中。你的目标是可读、流畅的文本，自然地引导读者理解想法。
```

### 提示链 (Prompt Chaining)

与之前的技术不同，提示链无法在单个提示中实现。链式提示将复杂任务分解为具有单独提示的较小顺序步骤。每个提示处理一个阶段，输出反馈到下一个指令中。

这种方法通过使每个单独的任务更容易，以延迟换取更高的准确性。通常，这种技术将使用工作流或编程方式实现，但你也可以在收到回复后手动提供提示。

**示例：研究摘要**

1.  **第一个提示**："总结这篇涵盖方法论、发现和临床意义的医学论文。"

2.  **第二个提示**："审查上面的摘要，检查准确性、清晰度和完整性。提供分级反馈。"

3.  **第三个提示**："根据此反馈改进摘要：[来自第 2 步的反馈]"

每个阶段都通过重点指令进行改进。

**何时使用提示链**：

*   你有一个需要分解为步骤的复杂请求
*   你需要迭代改进
*   你正在做多阶段分析
*   中间验证增加价值
*   单个提示产生不一致的结果

**权衡**：链式提示增加了延迟（多个 API 调用），但通常显著提高了复杂任务的准确性和可靠性。

## 你可能听说过的技术

一些在早期 AI 模型中流行的提示工程技术，在像 Claude 这样的模型中已不太必要。但是，你仍可能在旧文档中遇到它们，或者发现它们在特定情况下很有用。

### 用于结构的 XML 标签

XML 标签曾经是为提示添加结构和清晰度的推荐方式，特别是在包含大量数据时。虽然现代模型在没有 XML 标签的情况下也能更好地理解结构，但它们在特定情况下仍然有用。

**示例**：

```plaintext
<athlete_information>
- Height: 6'2"
- Weight: 180 lbs
- Goal: Build muscle
- Dietary restrictions: Vegetarian
</athlete_information>

根据上面的运动员信息生成膳食计划。
```

**XML 标签可能仍有帮助的情况**：

*   你正在处理混合多种类型内容的极其复杂的提示
*   你需要绝对确定内容边界
*   你正在使用旧版本的模型

**现代替代方案**：对于大多数用例，清晰的标题、空白和明确的语言（"使用下面的运动员信息..."）同样有效，且开销更小。

### 角色提示

角色提示在你措辞查询的方式中定义专家角色和视角。虽然这可能是有效的，但现代模型足够复杂，通常不需要笨拙的角色提示。

**示例**："你是一名财务顾问。分析这个投资组合..."

**重要警告**：不要过度限制角色。"你是一个乐于助人的助手" 通常比 "你是一个世界知名的专家，只说技术术语，从不犯错" 要好。过于具体的角色可能会限制 AI 的有用性。

**角色提示可能有所帮助的情况**：

*   你需要跨多个输出保持一致的语气
*   你正在构建一个需要特定角色的应用程序
*   你想要针对复杂主题的领域专业知识框架

**现代替代方案**：通常，明确你想要什么视角更有效："分析这个投资组合，关注风险承受能力和长期增长潜力"，而不是分配一个角色。

在 Claude 中 [尝试](https://preview.claude.ai/new)。

## 融会贯通

你现在已经看到了孤立的各种技术，但当你战略性地组合它们时，它们真正的力量才会显现出来。提示工程的艺术不在于使用每一种可用的技术——而在于为你的特定需求选择正确的组合。

**组合多种技术的示例**：

```less
从这份季度报告中提取关键财务指标，并以 JSON 格式呈现。

我需要这些数据用于自动处理，因此至关重要的是，你的响应仅包含有效的 JSON，没有任何开场白或解释。

使用此结构：
{
  "revenue": "带单位的数值",
  "profit_margin": "百分比",
  "growth_rate": "百分比"
}

如果报告中未明确说明任何指标，请使用 null 而不是猜测。

以左大括号开始你的响应：{
```

这个提示结合了：

*   明确的指令（确切提取什么）
*   背景（为什么格式很重要）
*   示例结构（展示格式）
*   允许表达不确定性（如果不确定则使用 null）
*   格式控制（以左大括号开始）

## 选择正确的技术

并非每个提示都需要每种技术。这是一个决策框架：

**从这里开始：**

1.  你的请求清晰明确吗？如果不，先致力于清晰度
2.  任务简单吗？仅使用核心技术（具体、清晰、提供背景）
3.  任务需要特定格式吗？使用示例或预填
4.  任务复杂吗？考虑将其分解（链式）
5.  它需要推理吗？使用扩展思维（如果可用）或思维链

**技术选择指南**：

如果你需要... 使用...

特定输出格式 -> 示例、预填或明确的格式指令

逐步推理 -> 扩展思维 (Claude 4.x) 或思维链

复杂的多阶段任务 -> 提示链

透明推理 -> 带有结构化输出的思维链

防止幻觉 -> 允许说"我不知道"

## 常见提示问题故障排除

即使是出于好意的提示也可能产生意想不到的结果。以下是常见问题及其修复方法：

*   **问题：回答太笼统** → 解决方案：增加具体性、示例或明确要求全面的输出。要求 AI "超越基础"。
*   **问题：回答离题或未抓住重点** → 解决方案：更明确你的实际目标。提供关于你为什么要问的背景。
*   **问题：回答格式不一致** → 解决方案：添加示例（少样本）或使用预填来控制响应的开始。
*   **问题：任务太复杂，结果不可靠** → 解决方案：分解为多个提示（链式）。每个提示应该做好一件事。
*   **问题：AI 包含不必要的开场白** → 解决方案：使用预填或明确要求："跳过开场白，直奔答案。"
*   **问题：AI 编造信息** → 解决方案：明确允许在不确定时说"我不知道"。
*   **问题：AI 建议更改，而你想要实施** → 解决方案：明确行动："更改此函数" 而不是 "你能建议更改吗？"

**专业提示**：从简单开始，仅在需要时增加复杂性。测试每个添加，看看它是否真的改善了结果。

## 避免的常见错误

从这些常见的陷阱中学习，以节省时间并改进你的提示：

*   **不要过度工程化**：更长、更复杂的提示并不总是更好。
*   **不要忽视基础**：如果你的核心提示不清楚或模糊，高级技术也无济于事。
*   **不要假设 AI 会读心术**：具体说明你想要什么。把事情留得模棱两可会给 AI 误解的空间。
*   **不要一次使用所有技术**：选择解决你特定挑战的技术。
*   **不要忘记迭代**：第一个提示很少能完美工作。测试并改进。
*   **不要依赖过时的技术**：XML 标签和繁重的角色提示在现代模型中不太必要。从明确、清晰的指令开始。

## 提示工程注意事项

### 处理长内容

实施高级提示工程的挑战之一是，它通过额外的 token 使用增加了上下文开销。示例、多个提示、详细指令——它们都会消耗 token，而上下文管理本身就是一项技能。

请记住在有意义并证明其使用合理时使用提示工程技术。有关有效管理上下文的综合指导，请查看我们关于 [上下文工程](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents) 的博客文章。

**上下文感知改进**：现代 AI 模型，包括 Claude 4.x，已经显著提高了上下文感知能力，有助于解决历史上的"中间迷失 (lost-in-the-middle)"问题，即模型难以同等关注长上下文的所有部分。

**为什么任务拆分仍然有帮助**：即使有了这些改进，将大任务分解为更小的、离散的块仍然是一项有价值的技术——不是因为上下文限制，而是因为它帮助模型专注于在一组非常具体的要求和范围内做到最好。与试图在单个提示中完成多个目标相比，具有清晰边界的专注任务始终能产生更高质量的结果。

**策略**：处理长上下文时，清晰地组织你的信息，将最关键的细节放在开头或结尾。处理复杂任务时，考虑将它们分解为专注的子任务是否会提高每个组件的质量和可靠性。

### 好的提示是什么样的？

提示工程是一项技能，在你掌握它之前需要尝试几次。知道你是否做对的唯一方法是测试并观察。第一步就是你自己尝试。你会立即看到使用了和未使用我们在此涵盖的提示技术的查询之间的差异。

要真正磨练你的提示工程技能，你需要客观地衡量你的提示的有效性。好消息是，这正是我们在 [anthropic.skilljar.com](https://anthropic.skilljar.com/claude-with-the-anthropic-api) 上的提示工程课程中所涵盖的内容。

**快速评估技巧**：

*   输出是否符合你的具体要求？
*   你是一次尝试就得到了结果，还是需要多次迭代？
*   格式在多次尝试中是否一致？
*   你是否避免了上面列出的常见错误？

## 最后的建议

提示工程归根结底是关于沟通：说出最能帮助 AI 清楚理解你意图的语言。从本指南早期涵盖的核心技术开始。坚持使用它们，直到它们成为第二天性。只有当高级技术能解决特定问题时才分层使用它们。

记住：最好的提示不是最长或最复杂的。它是以最少的必要结构可靠地实现你目标的提示。随着你的练习，你会发展出一种直觉，知道哪些技术适合哪些情况。

向上下文工程的转变并没有削弱提示工程的重要性。事实上，提示工程是上下文工程中的一个基本构建块。每一个精心制作的提示都成为塑造 AI 行为的更大上下文的一部分，与对话历史、附加文件和系统指令一起工作，以创造更好的结果。

今天就开始在 Claude 中 [尝试提示](https://preview.claude.ai/new)。

## 额外资源

*   [提示工程文档](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/overview)
*   [交互式提示工程教程](https://github.com/anthropics/prompt-eng-interactive-tutorial)
*   [提示工程课程](https://anthropic.skilljar.com/claude-with-the-anthropic-api)
*   [上下文工程指南](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)
